{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxxOWz9dpsYj"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1uzH-ybgKrDjNPEvrfwpE47IpD8jKRfnM?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "###\t What is Multi-index?\n",
        "\n",
        "Multi-index is a RAG technique that involves using multiple separate indexes or databases to store and retrieve information. Instead of having a single, monolithic index, data is distributed across several specialized indexes. Each index can be optimized for different types of data or query patterns, allowing for more efficient and targeted.\n",
        "\n",
        "###  Multi-index RAG Implementation:\n",
        "\n",
        "1. **Retrieval from Multiple Indices:** We retrieve relevant documents from each vector store.\n",
        "2. **Context Combination:** We combine the retrieved documents from all sources into a single context.\n",
        "3. **Response Generation:** Using the combined context, we generate a final response to the original query.\n",
        "4. **Source Usage Explanation:** We generate an explanation of how information from different sources was used to answer the question.\n",
        "\n",
        "### 锔 Setup\n",
        "\n",
        "1. **[LLM](https://groq.com/):** Groq's free Open source LLM endpoints([Groq API Key](https://console.groq.com/keys))\n",
        "2. **[Vector Store](https://www.pinecone.io/learn/vector-database/):** [ChromaDB](https://www.trychroma.com/)\n",
        "3. **[Embedding Model](https://qdrant.tech/articles/what-are-embeddings/):** [nomic-embed-text-v1.5](https://www.nomic.ai/blog/posts/nomic-embed-text-v1)\n",
        "4. **[LLM Framework](https://python.langchain.com/v0.2/docs/introduction/):** LangChain\n",
        "5. **[Huggingface API Key](https://huggingface.co/settings/tokens)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3axTI0sp5Hg"
      },
      "source": [
        "# Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ShxTNxM5gqtr"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U \\\n",
        "     Sentence-transformers==3.0.1 \\\n",
        "     langchain==0.3.19 \\\n",
        "     langchain-groq==0.2.4 \\\n",
        "     langchain-chroma==0.2.2 \\\n",
        "     langchain-community==0.3.18 \\\n",
        "     langchain-huggingface==0.1.2 \\\n",
        "     einops==0.8.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Make sure NumPy and dependencies are consistent\n",
        "!pip install --force-reinstall --no-cache-dir numpy==1.26.4\n",
        "\n",
        "# 2. Rebuild dependent binary packages that might link to old NumPy\n",
        "!pip install --force-reinstall --no-cache-dir torch scikit-learn scipy\n",
        "\n",
        "# 3. (Optional, if using FAISS or Chroma vector stores)\n",
        "!pip install --force-reinstall --no-cache-dir faiss-cpu chromadb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "D6pn23jR2MVH",
        "outputId": "2f032f27-43f8-4e60-f780-aaf99a5f9c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m191.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.43.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.28.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e6d20bd27e37457888086514e311b3dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m179.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJ1vqs-p_Zx"
      },
      "source": [
        "### Import related libraries related to Langchain, HuggingfaceEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL-3LsYogoH5",
        "outputId": "83cc4b57-9ba3-4614-810f-911dcf111bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GT55z5AkhyOW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UeDlrgqI2A"
      },
      "source": [
        "#### Provide a Groq API key. You can create one to access free open-source models at the following link.\n",
        "\n",
        "[Groq API Creation Link](https://console.groq.com/keys)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobvrD3glfd4",
        "outputId": "b027a4e9-35f7-46f7-b5dc-3ef17cc256f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1dLpYboqeIK"
      },
      "source": [
        "# Provide Huggingface API Key. You can create Huggingface API key at following link\n",
        "\n",
        "[Huggingface API Creation Link](https://huggingface.co/settings/tokens)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ6scBGZlhpG",
        "outputId": "30e3ed16-7cac-4be1-ac24-bb33a3c410cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"HF_TOKEN\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaB23jlCpQhd"
      },
      "source": [
        "### Step 1: Load and preprocess data code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "azSUjUBugUz3"
      },
      "outputs": [],
      "source": [
        "def load_and_process_data(url):\n",
        "    # Load data from web\n",
        "    loader = WebBaseLoader(url)\n",
        "    data = loader.load()\n",
        "\n",
        "    # Split text into chunks (Experiment with Chunk Size and Chunk Overlap to get optimal chunking)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JkZFt0wxYQj"
      },
      "source": [
        "### Step 2: Create multiple vector stores code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IJBNL80WxUMe"
      },
      "outputs": [],
      "source": [
        "def create_vector_stores(chunks_list):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"nomic-ai/nomic-embed-text-v1.5\", model_kwargs = {'trust_remote_code': True})\n",
        "    vector_stores = []\n",
        "    for chunks in chunks_list:\n",
        "        vector_store = Chroma.from_documents(chunks, embeddings)\n",
        "        vector_stores.append(vector_store)\n",
        "    return vector_stores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGe14v-pxaj_"
      },
      "source": [
        "### Step 3: Mult-index-RAG related code\n",
        "\n",
        "1. **Retrieval from Multiple Indices:** We retrieve relevant documents from each vector store.\n",
        "2. **Context Combination:** We combine the retrieved documents from all sources into a single context.\n",
        "3. **Response Generation:** Using the combined context, we generate a final response to the original query.\n",
        "4. **Source Usage Explanation:** We generate an explanation of how information from different sources was used to answer the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_gAL7mH5xaBM"
      },
      "outputs": [],
      "source": [
        "def multi_index_rag(query, vector_stores, llm):\n",
        "    # Retrieve documents from each vector store\n",
        "    all_docs = []\n",
        "    for i, vector_store in enumerate(vector_stores):\n",
        "        docs = vector_store.similarity_search(query, k=3)  # Increased k to 3\n",
        "        all_docs.extend([f\"Source {i+1}: \" + doc.page_content for doc in docs])\n",
        "\n",
        "    # Combine retrieved documents\n",
        "    context = \"\\n\\n\".join(all_docs)\n",
        "\n",
        "    # Generate response using combined context\n",
        "    response_prompt = ChatPromptTemplate.from_template(\n",
        "        \"You are an AI assistant tasked with answering questions based on the provided context. \"\n",
        "        \"The context contains information from multiple sources related to AI, machine learning, and NLP. \"\n",
        "        \"Please analyze the context carefully and provide a comprehensive answer to the question. \"\n",
        "        \"If the context doesn't contain enough information, use your general knowledge to supplement the answer, \"\n",
        "        \"but prioritize information from the context when available.\\n\\n\"\n",
        "        \"Context:\\n{context}\\n\\n\"\n",
        "        \"Question: {query}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    response_chain = response_prompt | llm\n",
        "    try:\n",
        "        response = response_chain.invoke({\"context\": context, \"query\": query})\n",
        "        final_answer = response.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        final_answer = \"I apologize, but I encountered an error while generating the response.\"\n",
        "\n",
        "    # Generate explanation of source usage\n",
        "    explanation_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Based on the answer you provided, explain how information from different sources was used to answer the question. \"\n",
        "        \"If general knowledge was used to supplement the answer, mention that as well.\\n\\n\"\n",
        "        \"Context: {context}\\n\"\n",
        "        \"Question: {query}\\n\"\n",
        "        \"Answer: {answer}\\n\"\n",
        "        \"Explanation:\"\n",
        "    )\n",
        "    explanation_chain = explanation_prompt | llm\n",
        "    try:\n",
        "        explanation = explanation_chain.invoke({\"context\": context, \"query\": query, \"answer\": final_answer})\n",
        "        source_explanation = explanation.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating explanation: {e}\")\n",
        "        source_explanation = \"Unable to generate explanation due to an error.\"\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_answer,\n",
        "        \"source_explanation\": source_explanation,\n",
        "        \"retrieved_context\": context\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elvvxh_A0VdM",
        "outputId": "2fc87492-5fbd-4b0a-c0ba-07d6aa5051a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "VHsagH5I0cP7",
        "outputId": "d20389a1-fbbb-4229-9dcb-1f63ad15ffae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/62.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/16.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m11.3/16.6 MB\u001b[0m \u001b[31m339.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m386.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-chroma 0.2.2 requires numpy<2.0.0,>=1.26.2; python_version >= \"3.12\", but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ed1dc95638f14262b43278611463ffc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall --no-cache-dir chromadb llama-index faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ousRPmpo0aiy",
        "outputId": "caf9fa0d-22fc-41d4-da34-c2d362a2a621"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pydantic>=1.9 (from chromadb)\n",
            "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting numpy>=1.22.5 (from chromadb)\n",
            "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m316.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting typing-extensions>=4.5.0 (from chromadb)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m344.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm>=4.65.0 (from chromadb)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m312.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyyaml>=6.0.0 (from chromadb)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m188.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting jsonschema>=4.19.0 (from chromadb)\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.8 (from llama-index)\n",
            "  Downloading llama_index_core-0.14.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.6.8-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting packaging (from faiss-cpu)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting anyio (from httpx>=0.27.0->chromadb)\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting certifi (from httpx>=0.27.0->chromadb)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx>=0.27.0->chromadb)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.19.0->chromadb)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
            "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
            "  Downloading rpds_py-0.28.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting six>=1.9.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.5.3 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting requests (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading llama_index_workflows-2.11.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting nest-asyncio<2,>=1.5.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting networkx>=3.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=9.0.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting platformdirs (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting openai>=1.1.0 (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
            "  Downloading openai-2.7.2-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pandas<2.3.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m297.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting click (from nltk>3.8.1->llama-index)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting joblib (from nltk>3.8.1->llama-index)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m269.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=1.9->chromadb)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=1.9->chromadb)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic>=1.9->chromadb)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->chromadb)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-1.1.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m242.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jinja2 (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
            "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m280.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.14.8-py3-none-any.whl (7.4 kB)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m248.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m208.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m339.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m336.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m363.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m403.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.8-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m238.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m399.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.8-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m292.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m377.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m265.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m163.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m212.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m207.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m184.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m228.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m233.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m136.3/136.3 kB\u001b[0m \u001b[31m221.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m213.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m209.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m350.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m358.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m279.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m374.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m255.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m362.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m352.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m324.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m258.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m400.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m373.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m388.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m223.1/223.1 kB\u001b[0m \u001b[31m430.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m400.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m315.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-1.1.3-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m515.5/515.5 kB\u001b[0m \u001b[31m373.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading llama_index_workflows-2.11.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m353.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m347.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m331.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m437.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.7.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m423.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m359.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m263.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m325.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m382.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m435.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m357.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m333.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m438.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m339.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rpds_py-0.28.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m211.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m448.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m354.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m356.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m234.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m241.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m282.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m415.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m372.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m302.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m416.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m359.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m389.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m408.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m211.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m402.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m309.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m311.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m425.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m420.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m340.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m327.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m335.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m436.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m441.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m296.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m224.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m225.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m298.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m353.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a618c5a9232405dcddf9a3ef4c0fd7541a7b153dda3d7a006fb693e8c365b118\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u6h8o2ny/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: striprtf, pytz, pypika, mpmath, flatbuffers, filetype, durationpy, dirtyjson, zipp, wrapt, websockets, websocket-client, uvloop, urllib3, tzdata, typing-extensions, tqdm, tenacity, sympy, soupsieve, sniffio, six, shellingham, setuptools, rpds-py, regex, pyyaml, python-dotenv, pyproject_hooks, pypdf, pygments, pybase64, pyasn1, protobuf, propcache, platformdirs, pillow, packaging, overrides, orjson, oauthlib, numpy, networkx, nest-asyncio, mypy-extensions, multidict, mmh3, mdurl, MarkupSafe, joblib, jiter, importlib-resources, idna, humanfriendly, httptools, hf-xet, h11, greenlet, fsspec, frozenlist, filelock, distro, defusedxml, colorama, click, charset_normalizer, certifi, cachetools, bcrypt, backoff, attrs, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspection, typing-inspect, typer-slim, sqlalchemy, rsa, requests, referencing, python-dateutil, pydantic-core, pyasn1-modules, opentelemetry-proto, nltk, marshmallow, markdown-it-py, jinja2, importlib-metadata, httpcore, grpcio, griffe, googleapis-common-protos, faiss-cpu, deprecated, coloredlogs, build, beautifulsoup4, anyio, aiosqlite, aiosignal, watchfiles, tiktoken, rich, requests-oauthlib, pydantic, posthog, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, httpx, google-auth, dataclasses-json, aiohttp, typer, opentelemetry-semantic-conventions, openai, llama-index-instrumentation, llama-cloud, kubernetes, jsonschema, huggingface-hub, banks, tokenizers, opentelemetry-sdk, llama-index-workflows, opentelemetry-exporter-otlp-proto-grpc, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, chromadb, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: pypika\n",
            "    Found existing installation: PyPika 0.48.9\n",
            "    Uninstalling PyPika-0.48.9:\n",
            "      Successfully uninstalled PyPika-0.48.9\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.9.23\n",
            "    Uninstalling flatbuffers-25.9.23:\n",
            "      Successfully uninstalled flatbuffers-25.9.23\n",
            "  Attempting uninstall: durationpy\n",
            "    Found existing installation: durationpy 0.10\n",
            "    Uninstalling durationpy-0.10:\n",
            "      Successfully uninstalled durationpy-0.10\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.23.0\n",
            "    Uninstalling zipp-3.23.0:\n",
            "      Successfully uninstalled zipp-3.23.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.3\n",
            "    Uninstalling wrapt-1.17.3:\n",
            "      Successfully uninstalled wrapt-1.17.3\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.9.0\n",
            "    Uninstalling websocket-client-1.9.0:\n",
            "      Successfully uninstalled websocket-client-1.9.0\n",
            "  Attempting uninstall: uvloop\n",
            "    Found existing installation: uvloop 0.22.1\n",
            "    Uninstalling uvloop-0.22.1:\n",
            "      Successfully uninstalled uvloop-0.22.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.5.0\n",
            "    Uninstalling tenacity-8.5.0:\n",
            "      Successfully uninstalled tenacity-8.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.8\n",
            "    Uninstalling soupsieve-2.8:\n",
            "      Successfully uninstalled soupsieve-2.8\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.28.0\n",
            "    Uninstalling rpds-py-0.28.0:\n",
            "      Successfully uninstalled rpds-py-0.28.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pyproject_hooks\n",
            "    Found existing installation: pyproject_hooks 1.2.0\n",
            "    Uninstalling pyproject_hooks-1.2.0:\n",
            "      Successfully uninstalled pyproject_hooks-1.2.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.4.1\n",
            "    Uninstalling propcache-0.4.1:\n",
            "      Successfully uninstalled propcache-0.4.1\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.5.0\n",
            "    Uninstalling platformdirs-4.5.0:\n",
            "      Successfully uninstalled platformdirs-4.5.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.7.0\n",
            "    Uninstalling overrides-7.7.0:\n",
            "      Successfully uninstalled overrides-7.7.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.4\n",
            "    Uninstalling orjson-3.11.4:\n",
            "      Successfully uninstalled orjson-3.11.4\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.3.1\n",
            "    Uninstalling oauthlib-3.3.1:\n",
            "      Successfully uninstalled oauthlib-3.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.6.0\n",
            "    Uninstalling nest-asyncio-1.6.0:\n",
            "      Successfully uninstalled nest-asyncio-1.6.0\n",
            "  Attempting uninstall: mypy-extensions\n",
            "    Found existing installation: mypy_extensions 1.1.0\n",
            "    Uninstalling mypy_extensions-1.1.0:\n",
            "      Successfully uninstalled mypy_extensions-1.1.0\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: mmh3\n",
            "    Found existing installation: mmh3 5.2.0\n",
            "    Uninstalling mmh3-5.2.0:\n",
            "      Successfully uninstalled mmh3-5.2.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: humanfriendly\n",
            "    Found existing installation: humanfriendly 10.0\n",
            "    Uninstalling humanfriendly-10.0:\n",
            "      Successfully uninstalled humanfriendly-10.0\n",
            "  Attempting uninstall: httptools\n",
            "    Found existing installation: httptools 0.7.1\n",
            "    Uninstalling httptools-0.7.1:\n",
            "      Successfully uninstalled httptools-0.7.1\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.2.4\n",
            "    Uninstalling greenlet-3.2.4:\n",
            "      Successfully uninstalled greenlet-3.2.4\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: defusedxml\n",
            "    Found existing installation: defusedxml 0.7.1\n",
            "    Uninstalling defusedxml-0.7.1:\n",
            "      Successfully uninstalled defusedxml-0.7.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.10.5\n",
            "    Uninstalling certifi-2025.10.5:\n",
            "      Successfully uninstalled certifi-2025.10.5\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: bcrypt\n",
            "    Found existing installation: bcrypt 5.0.0\n",
            "    Uninstalling bcrypt-5.0.0:\n",
            "      Successfully uninstalled bcrypt-5.0.0\n",
            "  Attempting uninstall: backoff\n",
            "    Found existing installation: backoff 2.2.1\n",
            "    Uninstalling backoff-2.2.1:\n",
            "      Successfully uninstalled backoff-2.2.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.38.0\n",
            "    Uninstalling uvicorn-0.38.0:\n",
            "      Successfully uninstalled uvicorn-0.38.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: typing-inspect\n",
            "    Found existing installation: typing-inspect 0.9.0\n",
            "    Uninstalling typing-inspect-0.9.0:\n",
            "      Successfully uninstalled typing-inspect-0.9.0\n",
            "  Attempting uninstall: typer-slim\n",
            "    Found existing installation: typer-slim 0.20.0\n",
            "    Uninstalling typer-slim-0.20.0:\n",
            "      Successfully uninstalled typer-slim-0.20.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.44\n",
            "    Uninstalling SQLAlchemy-2.0.44:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.44\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.37.0\n",
            "    Uninstalling referencing-0.37.0:\n",
            "      Successfully uninstalled referencing-0.37.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.38.0\n",
            "    Uninstalling opentelemetry-proto-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: marshmallow\n",
            "    Found existing installation: marshmallow 3.26.1\n",
            "    Uninstalling marshmallow-3.26.1:\n",
            "      Successfully uninstalled marshmallow-3.26.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.72.0\n",
            "    Uninstalling googleapis-common-protos-1.72.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.72.0\n",
            "  Attempting uninstall: coloredlogs\n",
            "    Found existing installation: coloredlogs 15.0.1\n",
            "    Uninstalling coloredlogs-15.0.1:\n",
            "      Successfully uninstalled coloredlogs-15.0.1\n",
            "  Attempting uninstall: build\n",
            "    Found existing installation: build 1.3.0\n",
            "    Uninstalling build-1.3.0:\n",
            "      Successfully uninstalled build-1.3.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.5\n",
            "    Uninstalling beautifulsoup4-4.13.5:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.5\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: watchfiles\n",
            "    Found existing installation: watchfiles 1.1.1\n",
            "    Uninstalling watchfiles-1.1.1:\n",
            "      Successfully uninstalled watchfiles-1.1.1\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.10\n",
            "    Uninstalling pydantic-2.11.10:\n",
            "      Successfully uninstalled pydantic-2.11.10\n",
            "  Attempting uninstall: posthog\n",
            "    Found existing installation: posthog 7.0.0\n",
            "    Uninstalling posthog-7.0.0:\n",
            "      Successfully uninstalled posthog-7.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.38.0\n",
            "    Uninstalling opentelemetry-api-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.38.0\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.23.2\n",
            "    Uninstalling onnxruntime-1.23.2:\n",
            "      Successfully uninstalled onnxruntime-1.23.2\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: dataclasses-json\n",
            "    Found existing installation: dataclasses-json 0.6.7\n",
            "    Uninstalling dataclasses-json-0.6.7:\n",
            "      Successfully uninstalled dataclasses-json-0.6.7\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.2\n",
            "    Uninstalling aiohttp-3.13.2:\n",
            "      Successfully uninstalled aiohttp-3.13.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.20.0\n",
            "    Uninstalling typer-0.20.0:\n",
            "      Successfully uninstalled typer-0.20.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: kubernetes\n",
            "    Found existing installation: kubernetes 34.1.0\n",
            "    Uninstalling kubernetes-34.1.0:\n",
            "      Successfully uninstalled kubernetes-34.1.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.38.0\n",
            "    Uninstalling opentelemetry-sdk-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.38.0\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.6.3\n",
            "    Uninstalling chromadb-0.6.3:\n",
            "      Successfully uninstalled chromadb-0.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "langchain-chroma 0.2.2 requires chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0, but you have chromadb 1.3.4 which is incompatible.\n",
            "langchain-chroma 0.2.2 requires numpy<2.0.0,>=1.26.2; python_version >= \"3.12\", but you have numpy 2.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.43.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "google-auth-oauthlib 1.2.3 requires google-auth<2.42.0,>=2.15.0, but you have google-auth 2.43.0 which is incompatible.\n",
            "transformers 4.57.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.1.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.0 which is incompatible.\n",
            "bigframes 2.28.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 aiosqlite-0.21.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 backoff-2.2.1 banks-2.2.0 bcrypt-5.0.0 beautifulsoup4-4.14.2 build-1.3.0 cachetools-6.2.1 certifi-2025.11.12 charset_normalizer-3.4.4 chromadb-1.3.4 click-8.3.0 colorama-0.4.6 coloredlogs-15.0.1 dataclasses-json-0.6.7 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 durationpy-0.10 faiss-cpu-1.12.0 filelock-3.20.0 filetype-1.2.0 flatbuffers-25.9.23 frozenlist-1.8.0 fsspec-2025.10.0 google-auth-2.43.0 googleapis-common-protos-1.72.0 greenlet-3.2.4 griffe-1.15.0 grpcio-1.76.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 huggingface-hub-1.1.3 humanfriendly-10.0 idna-3.11 importlib-metadata-8.7.0 importlib-resources-6.5.2 jinja2-3.1.6 jiter-0.12.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kubernetes-34.1.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.8 llama-index-cli-0.5.3 llama-index-core-0.14.8 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.8 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.1 llama-parse-0.6.54 markdown-it-py-4.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 multidict-6.7.0 mypy-extensions-1.1.0 nest-asyncio-1.6.0 networkx-3.5 nltk-3.9.2 numpy-2.3.4 oauthlib-3.3.1 onnxruntime-1.23.2 openai-2.7.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 orjson-3.11.4 overrides-7.7.0 packaging-25.0 pandas-2.2.3 pillow-12.0.0 platformdirs-4.5.0 posthog-5.4.0 propcache-0.4.1 protobuf-6.33.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.12.4 pydantic-core-2.41.5 pygments-2.19.2 pypdf-6.2.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rich-14.2.0 rpds-py-0.28.0 rsa-4.9.1 setuptools-80.9.0 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 soupsieve-2.8 sqlalchemy-2.0.44 striprtf-0.0.26 sympy-1.14.0 tenacity-9.1.2 tiktoken-0.12.0 tokenizers-0.22.1 tqdm-4.67.1 typer-0.20.0 typer-slim-0.20.0 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.3.0 uvicorn-0.38.0 uvloop-0.22.1 watchfiles-1.1.1 websocket-client-1.9.0 websockets-15.0.1 wrapt-1.17.3 yarl-1.22.0 zipp-3.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "aiohappyeyeballs",
                  "aiohttp",
                  "aiosignal",
                  "annotated_types",
                  "anyio",
                  "attr",
                  "bs4",
                  "certifi",
                  "click",
                  "dateutil",
                  "defusedxml",
                  "distro",
                  "filelock",
                  "frozenlist",
                  "google",
                  "h11",
                  "httpcore",
                  "httpx",
                  "idna",
                  "importlib_metadata",
                  "markupsafe",
                  "mpmath",
                  "multidict",
                  "numpy",
                  "opentelemetry",
                  "orjson",
                  "packaging",
                  "platformdirs",
                  "propcache",
                  "pydantic",
                  "regex",
                  "requests",
                  "rich",
                  "six",
                  "sniffio",
                  "soupsieve",
                  "sympy",
                  "tenacity",
                  "tokenizers",
                  "tqdm",
                  "typing_inspection",
                  "urllib3",
                  "yarl",
                  "zipp"
                ]
              },
              "id": "793299b2f9b74c719642952ec07ba60b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFcan5TryUca"
      },
      "source": [
        "### Step 4: Create chunk of web data to Chroma Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrAQVOhXw6QH",
        "outputId": "7518695e-60cf-44ae-c377-008b5793ace9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic_hyphen_ai.nomic_hyphen_bert_hyphen_2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "# Load and process data\n",
        "urls = [\n",
        "        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
        "        \"https://en.wikipedia.org/wiki/Machine_learning\",\n",
        "        \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
        "      ]\n",
        "chunks_list = [load_and_process_data(url) for url in urls]\n",
        "\n",
        "# Create multiple vector stores\n",
        "vector_stores = create_vector_stores(chunks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FShzccEf2Z2t"
      },
      "source": [
        "### Step 5: Run Multi-index RAG\n",
        "\n",
        "This implementation shows the key parts of Multi-index RAG:\n",
        "\n",
        "1. Use of multiple vector stores representing different sources or types of information\n",
        "2. Retrieval and combination of information from multiple sources\n",
        "3. Generation of a comprehensive response using the combined information\n",
        "Explanation of how different sources contributed to the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XXZ1eC7i2UKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc62eeae-72e4-433e-ab83-a01971efd4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do AI, machine learning, and NLP relate to each other in modern applications?\n",
            "\n",
            "Final Answer:\n",
            "Based on the provided context, it is evident that AI, machine learning, and NLP are interconnected concepts that have been a part of AI from the beginning. Here's a comprehensive explanation of their relationship in modern applications:\n",
            "\n",
            "1. **Machine Learning as a subset of AI**: Machine learning is the study of programs that can improve their performance on a given task automatically (Source 1, Source 2, and Source 3). This means that machine learning is a key component of AI, enabling programs to learn and improve over time.\n",
            "\n",
            "2. **NLP as a technology powering Document AI**: A Document AI platform sits on top of NLP technology, enabling users to train a computer to extract specific data from different document types (Source 1, Source 2, and Source 3). This demonstrates how NLP is used to power modern AI applications, such as Document AI.\n",
            "\n",
            "3. **NLP as an enabler of non-technical teams**: NLP-powered Document AI enables non-technical teams, such as lawyers, business analysts, and accountants, to quickly access information hidden in documents (Source 1, Source 2, and Source 3). This highlights how NLP is used to make AI applications more accessible to a wider range of users.\n",
            "\n",
            "4. **Dialogue management as a computer system intended to converse with humans**: Dialogue management is a computer system intended to converse with humans (Source 1, Source 2, and Source 3). This suggests that AI, machine learning, and NLP are also used in applications that involve human-computer interaction.\n",
            "\n",
            "In modern applications, AI, machine learning, and NLP are often used together to create powerful systems that can learn, reason, and interact with humans. For example, a Document AI platform that uses NLP to extract data from documents and machine learning to improve its performance over time is a modern application that combines these three concepts.\n",
            "\n",
            "In summary, AI, machine learning, and NLP are interconnected concepts that have been a part of AI from the beginning. NLP is used to power modern AI applications, such as Document AI, and machine learning is used to enable these applications to learn and improve over time.\n",
            "\n",
            "Source Usage Explanation:\n",
            "To answer the question, information from different sources was used to provide a comprehensive explanation of the relationship between AI, machine learning, and NLP in modern applications. The sources used were all identical, but I will break down the information used to answer the question.\n",
            "\n",
            "**Source 1, 2, and 3: Learning**\n",
            "\n",
            "The sources provided a definition of machine learning, stating that it is the study of programs that can improve their performance on a given task automatically. This information was used to establish that machine learning is a key component of AI, enabling programs to learn and improve over time.\n",
            "\n",
            "**Source 1, 2, and 3: Document AI**\n",
            "\n",
            "The sources provided information about Document AI, stating that it sits on top of NLP technology and enables users to train a computer to extract specific data from different document types. This information was used to demonstrate how NLP is used to power modern AI applications, such as Document AI.\n",
            "\n",
            "**Source 1, 2, and 3: Dialogue management**\n",
            "\n",
            "The sources provided information about dialogue management, stating that it is a computer system intended to converse with humans. This information was used to suggest that AI, machine learning, and NLP are also used in applications that involve human-computer interaction.\n",
            "\n",
            "**General knowledge**\n",
            "\n",
            "In addition to the information from the sources, general knowledge was used to supplement the answer. For example, the answer mentioned that a Document AI platform that uses NLP to extract data from documents and machine learning to improve its performance over time is a modern application that combines these three concepts. This information was not explicitly stated in the sources, but rather was inferred based on general knowledge of AI, machine learning, and NLP.\n",
            "\n",
            "Overall, the answer was able to provide a comprehensive explanation of the relationship between AI, machine learning, and NLP in modern applications by combining information from the sources and general knowledge.\n"
          ]
        }
      ],
      "source": [
        "# Example query\n",
        "query = \"How do AI, machine learning, and NLP relate to each other in modern applications?\"\n",
        "\n",
        "# Run Multi-index RAG\n",
        "result = multi_index_rag(query, vector_stores, llm)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(result[\"final_answer\"])\n",
        "print(\"\\nSource Usage Explanation:\")\n",
        "print(result[\"source_explanation\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MEwWi7R2-XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}